{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution Graph for Dallas Capital Query\n",
    "\n",
    "This notebook creates an attribution graph for the sentence:\n",
    "**\"Fact: The capital of the state containing Dallas is\"**\n",
    "\n",
    "We'll use the Gemma-2 (2B) model with GemmaScope transcoders to analyze the circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "- Load Model and Transcoders\n",
    "- Configure Attribution Parameters\n",
    "- Run Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch as t\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.utils import create_graph_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "login(os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/gemma-2-2b'\n",
    "transcoder_name = \"gemma\"  # GemmaScope transcoders\n",
    "\n",
    "print(f\"Loading {model_name} with {transcoder_name} transcoders...\")\n",
    "model = ReplacementModel.from_pretrained(\n",
    "    model_name, \n",
    "    transcoder_name, \n",
    "    dtype=t.bfloat16,\n",
    "    lazy_encoder=True\n",
    ")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution parameters\n",
    "prompt = \"Fact: The capital of the state containing Dallas is\"\n",
    "max_n_logits = 10\n",
    "desired_logit_prob = 0.95\n",
    "max_feature_nodes = 8192  # None for no limit, but will be slower\n",
    "batch_size = 256\n",
    "offload = 'cpu'  # Use 'disk' if running out of memory, None to keep everything on GPU\n",
    "verbose = True\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Max logits: {max_n_logits}\")\n",
    "print(f\"Desired logit probability: {desired_logit_prob}\")\n",
    "print(f\"Max feature nodes: {max_feature_nodes}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Offload strategy: {offload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning attribution...\\n\")\n",
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=offload,\n",
    "    verbose=verbose\n",
    ")\n",
    "print(\"\\nAttribution complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display Graph Statistics\n",
    "\n",
    "Let's examine the structure of the attribution graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of active features: {len(graph.active_features)}')\n",
    "print(f'length of adjacency matrix: {len(graph.adjacency_matrix)}')\n",
    "print(f'number of \"activation values\": {len(graph.activation_values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"GRAPH STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input information\n",
    "print(f\"\\nInput String: {graph.input_string}\")\n",
    "print(f\"Input Tokens: {graph.input_tokens.tolist()}\")\n",
    "print(f\"Number of positions: {graph.n_pos}\")\n",
    "\n",
    "# Feature information\n",
    "print(f\"\\nTotal active features: {len(graph.active_features)}\")\n",
    "print(f\"Selected features for graph: {len(graph.selected_features)}\")\n",
    "\n",
    "# Node structure\n",
    "n_layers = graph.cfg.n_layers\n",
    "n_pos = graph.n_pos\n",
    "n_error_nodes = n_layers * n_pos\n",
    "n_embed_nodes = n_pos\n",
    "n_logit_nodes = len(graph.logit_tokens)\n",
    "total_nodes = len(graph.selected_features) + n_error_nodes + n_embed_nodes + n_logit_nodes\n",
    "\n",
    "print(f\"\\nGraph Structure:\")\n",
    "print(f\"  Feature nodes: {len(graph.selected_features)}\")\n",
    "print(f\"  Error nodes: {n_error_nodes} ({n_layers} layers × {n_pos} positions)\")\n",
    "print(f\"  Embedding nodes: {n_embed_nodes}\")\n",
    "print(f\"  Logit nodes: {n_logit_nodes}\")\n",
    "print(f\"  Total nodes: {total_nodes}\")\n",
    "\n",
    "# Edge information\n",
    "adjacency_matrix = graph.adjacency_matrix\n",
    "total_edges = (adjacency_matrix != 0).sum().item()\n",
    "print(f\"\\nTotal non-zero edges: {total_edges:,}\")\n",
    "print(f\"Adjacency matrix shape: {adjacency_matrix.shape}\")\n",
    "print(f\"Adjacency matrix density: {total_edges / (adjacency_matrix.shape[0] * adjacency_matrix.shape[1]) * 100:.2f}%\")\n",
    "\n",
    "# Top logits\n",
    "print(f\"\\nTop {len(graph.logit_tokens)} predicted logits:\")\n",
    "for i, (token_id, prob) in enumerate(zip(graph.logit_tokens, graph.logit_probabilities)):\n",
    "    token_str = model.tokenizer.decode([token_id.item()])\n",
    "    print(f\"  {i+1}. '{token_str}' (token {token_id.item()}) - probability: {prob.item():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Topological Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_details(matrix_idx: int) -> tuple[int, int, int]:\n",
    "    assert matrix_idx < len(graph.selected_features), 'This node is not an active feature'\n",
    "    feature_idx = graph.selected_features[matrix_idx]\n",
    "    layer, token_pos, attribution_idx = graph.active_features[feature_idx]\n",
    "\n",
    "    return (layer.item(), token_pos.item(), attribution_idx.item())\n",
    "\n",
    "def matrix_idx_to_explanation(matrix_idx: int):\n",
    "    layer, __, feature_idx = get_feature_details(matrix_idx)\n",
    "\n",
    "    url = f'https://www.neuronpedia.org/gemma-2-2b/{layer}-gemmascope-transcoder-16k/{feature_idx}'\n",
    "    data = requests.get(url)\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "\n",
    "    body = soup.find('html').find('body')\n",
    "    idx_a = str(body).find('explanationModelName')\n",
    "    target_substring_large = str(body)[idx_a-200:idx_a]\n",
    "    assert 'description' in target_substring_large\n",
    "\n",
    "    idx_b = target_substring_large.find('description')\n",
    "    const_1 = 16\n",
    "    const_2 = 5\n",
    "    target_substring_final = target_substring_large[idx_b + const_1: -const_2]\n",
    "\n",
    "    return target_substring_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topological_order(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute topological order using Kahn's algorithm.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: torch.Tensor of shape (n_nodes, n_nodes)\n",
    "                         where adjacency_matrix[target, source] represents edge from source -> target\n",
    "    \n",
    "    Returns:\n",
    "        list: Topological order of node indices\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Compute in-degrees: for each node, count how many edges point TO it\n",
    "    in_degree = (adjacency_matrix != 0).sum(dim=1).cpu()\n",
    "    \n",
    "    # Initialize queue with nodes that have no incoming edges\n",
    "    queue = [i for i in range(n_nodes) if in_degree[i] == 0]\n",
    "    topo_order = []\n",
    "    \n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        topo_order.append(node)\n",
    "        \n",
    "        # For each outgoing edge from this node\n",
    "        outgoing_edges = (adjacency_matrix[:, node] != 0).cpu()\n",
    "        \n",
    "        for target in range(n_nodes):\n",
    "            if outgoing_edges[target]:\n",
    "                in_degree[target] -= 1\n",
    "                if in_degree[target] == 0:\n",
    "                    queue.append(target)\n",
    "    \n",
    "    if len(topo_order) != n_nodes:\n",
    "        print(f\"Warning: Graph contains a cycle! Only {len(topo_order)}/{n_nodes} nodes ordered.\")\n",
    "        remaining = [i for i in range(n_nodes) if i not in topo_order]\n",
    "        topo_order.extend(remaining)\n",
    "    \n",
    "    return topo_order\n",
    "\n",
    "def get_adjacency_without_error_nodes(adjacency_matrix):\n",
    "    # remove the error nodes from the adjacency matrix!\n",
    "    n_features = len(graph.selected_features)\n",
    "    n_error_nodes = len(graph.input_tokens) * model.cfg.n_layers\n",
    "\n",
    "    mask = t.ones_like(adjacency_matrix[0]).to(t.bool)\n",
    "    mask[n_features : n_features + n_error_nodes] = False\n",
    "    updated_matrix = adjacency_matrix[mask][:, mask]\n",
    "\n",
    "    return updated_matrix\n",
    "\n",
    "adjacency_matrix = graph.adjacency_matrix\n",
    "\n",
    "print(\"Computing topological order of the attribution graph...\")\n",
    "topo_order = compute_topological_order(adjacency_matrix)\n",
    "print(f\"Topological order computed: {len(topo_order)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_details(node: int):\n",
    "    '''\n",
    "    layers range from -1 to 26  \n",
    "    layer -1 is the embedding  \n",
    "    layer 26 is the logits  \n",
    "\n",
    "    token positions range from 1 to 10  \n",
    "    (BOS is token 0; it is excluded)\n",
    "    '''\n",
    "    n_features = len(graph.selected_features)\n",
    "    n_error_nodes = len(graph.input_tokens) * model.cfg.n_layers\n",
    "    n_embed_nodes = len(graph.input_tokens)\n",
    "    n_logit_nodes = len(graph.logit_tokens)\n",
    "\n",
    "    if node < n_features:\n",
    "        layer, token_pos, __ = get_feature_details(node)\n",
    "    elif node < (n_features + n_error_nodes):\n",
    "        error_number = node - n_features\n",
    "        token_pos = error_number % 11\n",
    "        layer = error_number // 11\n",
    "    elif node < (n_features + n_error_nodes + n_embed_nodes):\n",
    "        layer = -1\n",
    "        token_pos = node - (n_features + n_error_nodes)\n",
    "    else:\n",
    "        layer = model.cfg.n_layers\n",
    "        token_pos = len(graph.input_tokens) - 1\n",
    "\n",
    "    return layer, token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_topological_sort(topological_sort, n_error_nodes=286):\n",
    "    '''\n",
    "    the only 'illegal moves' are  \n",
    "    (a) moving to same token, previous layer  \n",
    "    (b) moving to previous token, previous layer  \n",
    "    '''\n",
    "\n",
    "    prev_layer = -1\n",
    "    prev_token_pos = 0\n",
    "\n",
    "    for idx, node in enumerate(topological_sort[286:]):\n",
    "        layer, token_pos = get_node_details(node)\n",
    "        if (layer < prev_layer) and (token_pos <= prev_token_pos):\n",
    "            print(f'error in topological sort at idx: {idx}')\n",
    "        \n",
    "    print(f'topological sort is okay!')\n",
    "\n",
    "test_topological_sort(topo_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find top-k most influential paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from circuit_tracer.graph import compute_node_influence\n",
    "\n",
    "@dataclass\n",
    "class Path:\n",
    "    \"\"\"Represents a path through the attribution graph.\"\"\"\n",
    "    nodes: List[int]\n",
    "    edges: List[float]\n",
    "    score: float\n",
    "    # averaged_score: float\n",
    "    final_score: float\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def get_node_types(self, graph) -> List[str]:\n",
    "        \"\"\"Return node types: 'feature', 'error', 'embed', 'logit'.\"\"\"\n",
    "        n_features = len(graph.selected_features)\n",
    "        n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "        n_embeds = graph.n_pos\n",
    "        \n",
    "        types = []\n",
    "        for node in self.nodes:\n",
    "            if node < n_features:\n",
    "                types.append('feature')\n",
    "            elif node < n_features + n_errors:\n",
    "                types.append('error')\n",
    "            elif node < n_features + n_errors + n_embeds:\n",
    "                types.append('embed')\n",
    "            else:\n",
    "                types.append('logit')\n",
    "        return types\n",
    "    \n",
    "    def get_node_descriptions(self, graph, tokenizer) -> List[str]:\n",
    "        \"\"\"Return human-readable descriptions for each node.\"\"\"\n",
    "        descriptions = []\n",
    "        n_features = len(graph.selected_features)\n",
    "        n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "        n_embeds = graph.n_pos\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            if node < n_features:\n",
    "                layer, pos, feat_idx = graph.active_features[graph.selected_features[node]].tolist()\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Feature L{layer}:F{feat_idx} @ pos {pos} ('{token}')\")\n",
    "            elif node < n_features + n_errors:\n",
    "                error_idx = node - n_features\n",
    "                layer = error_idx // graph.n_pos\n",
    "                pos = error_idx % graph.n_pos\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Error L{layer} @ pos {pos} ('{token}')\")\n",
    "            elif node < n_features + n_errors + n_embeds:\n",
    "                pos = node - n_features - n_errors\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Embedding @ pos {pos} ('{token}')\")\n",
    "            else:\n",
    "                logit_idx = node - n_features - n_errors - n_embeds\n",
    "                token = tokenizer.decode([graph.logit_tokens[logit_idx]])\n",
    "                prob = graph.logit_probabilities[logit_idx].item()\n",
    "                descriptions.append(f\"Logit '{token}' (p={prob:.4f})\")\n",
    "        \n",
    "        return descriptions\n",
    "\n",
    "\n",
    "def find_k_best_paths_dp(adj_matrix, source_nodes, sink_node, topo_order, k=10, verbose=True):\n",
    "    \"\"\"OPTIMIZED: Find top-K paths using DP. Stores lightweight references, reconstructs at end.\"\"\"\n",
    "    best_path_refs = {}\n",
    "    best_path_refs[sink_node] = [(None, None, 1.0)]\n",
    "    \n",
    "    iterator = reversed(topo_order) if not verbose else tqdm(\n",
    "        reversed(topo_order), desc=\"DP path finding (optimized)\", total=len(topo_order)\n",
    "    )\n",
    "    \n",
    "    for node in iterator:\n",
    "        if node == sink_node:\n",
    "            continue\n",
    "        \n",
    "        outgoing_weights = adj_matrix[:, node]\n",
    "        successors = t.where(outgoing_weights != 0)[0]\n",
    "        \n",
    "        if len(successors) == 0:\n",
    "            best_path_refs[node] = []\n",
    "            continue\n",
    "        \n",
    "        candidate_refs = []\n",
    "        for succ in successors:\n",
    "            succ_idx = succ.item()\n",
    "            if succ_idx not in best_path_refs or len(best_path_refs[succ_idx]) == 0:\n",
    "                continue\n",
    "            \n",
    "            edge_weight = outgoing_weights[succ].item()\n",
    "            for succ_next, succ_edge, path_score in best_path_refs[succ_idx]:\n",
    "                new_score = abs(edge_weight) * path_score\n",
    "                candidate_refs.append((succ_idx, edge_weight, new_score))\n",
    "        \n",
    "        candidate_refs.sort(key=lambda x: x[2], reverse=True)\n",
    "        best_path_refs[node] = candidate_refs[:k]\n",
    "    \n",
    "    def reconstruct_path(start_node, path_ref_index):\n",
    "        \"\"\"Reconstruct full path by following successor chain.\"\"\"\n",
    "        nodes, edges = [start_node], []\n",
    "        current_node, current_ref_idx = start_node, path_ref_index\n",
    "        \n",
    "        while True:\n",
    "            next_node, edge_weight, score = best_path_refs[current_node][current_ref_idx]\n",
    "            if next_node is None:\n",
    "                break\n",
    "            \n",
    "            nodes.append(next_node)\n",
    "            edges.append(edge_weight)\n",
    "            current_node = next_node\n",
    "            \n",
    "            target_score = score / abs(edge_weight)\n",
    "            current_ref_idx = 0\n",
    "            for i, (nn, ne, ns) in enumerate(best_path_refs[current_node]):\n",
    "                if abs(ns - target_score) < 1e-9:\n",
    "                    current_ref_idx = i\n",
    "                    break\n",
    "        \n",
    "        return Path(nodes=nodes, edges=edges, score=best_path_refs[start_node][path_ref_index][2], final_score=0.0)\n",
    "    \n",
    "    all_source_paths = []\n",
    "    for source in source_nodes:\n",
    "        if source in best_path_refs and len(best_path_refs[source]) > 0:\n",
    "            for path_idx in range(len(best_path_refs[source])):\n",
    "                all_source_paths.append(reconstruct_path(source, path_idx))\n",
    "\n",
    "    return all_source_paths\n",
    "    \n",
    "    # for path in all_source_paths:\n",
    "    #     path.averaged_score = path.score / len(path.edges)\n",
    "    #     path.final_score = sum(path.edges) / len(path.edges)\n",
    "    \n",
    "    # all_source_paths.sort(key=lambda p: p.final_score, reverse=True)\n",
    "    # return all_source_paths[:k]\n",
    "\n",
    "\n",
    "print(\"✅ Path finding functions loaded (optimized version)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define node indices\n",
    "n_features = len(graph.selected_features)\n",
    "n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "n_embeds = graph.n_pos\n",
    "n_logits = len(graph.logit_tokens)\n",
    "\n",
    "embed_start = n_features + n_errors\n",
    "embed_end = embed_start + n_embeds\n",
    "embed_nodes = list(range(embed_start, embed_end))\n",
    "austin_logit = embed_end  # Index 8489\n",
    "\n",
    "print(f\"Finding top-10 complete paths: Embeddings [{embed_start}:{embed_end}] → Austin [{austin_logit}]\")\n",
    "print()\n",
    "\n",
    "# Find complete paths\n",
    "all_complete_paths = find_k_best_paths_dp(\n",
    "    adj_matrix=adjacency_matrix,\n",
    "    source_nodes=embed_nodes,\n",
    "    sink_node=austin_logit,\n",
    "    topo_order=topo_order,\n",
    "    k=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_complete_paths:\n",
    "    mylen = len(path.edges)\n",
    "    if mylen <= 24:\n",
    "        print(mylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = all_complete_paths[0]\n",
    "# print(f'len graph active featrues: {len(graph.active_features)}')\n",
    "\n",
    "for node in mypath.nodes:\n",
    "    # print(f'node: {node}')\n",
    "    try:\n",
    "        node_explanation = matrix_idx_to_explanation(node)\n",
    "        print(node_explanation)\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_complete_paths:\n",
    "    path.final_score = sum(path.edges) / len(path.edges)\n",
    "\n",
    "all_complete_paths_sorted = sorted(all_complete_paths, key=lambda p: p.final_score, reverse=True)\n",
    "top_k_complete_paths = all_complete_paths_sorted[:10]\n",
    "\n",
    "print(f\"\\n✅ Found {len(top_k_complete_paths)} complete paths!\")\n",
    "print()\n",
    "\n",
    "# Display paths\n",
    "for rank, path in enumerate(top_k_complete_paths, 1):\n",
    "    node_descs = path.get_node_descriptions(graph, model.tokenizer)\n",
    "    node_types = path.get_node_types(graph)\n",
    "    \n",
    "    print(f\"Path #{rank} (Score: {path.final_score:.8f}, Length: {len(path)})\")\n",
    "    print(f\"  {' → '.join(node_types)}\")\n",
    "    print(f\"  Start: {node_descs[0]}\")\n",
    "    print(f\"  End: {node_descs[-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Paths to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_dataframe(paths, graph, tokenizer):\n",
    "    \"\"\"Convert list of Path objects to pandas DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for rank, path in enumerate(paths, 1):\n",
    "        node_types = path.get_node_types(graph)\n",
    "        node_descs = path.get_node_descriptions(graph, tokenizer)\n",
    "        \n",
    "        rows.append({\n",
    "            'rank': rank,\n",
    "            'influence_score': path.score,\n",
    "            'length': len(path),\n",
    "            'start_type': node_types[0],\n",
    "            'end_type': node_types[-1],\n",
    "            'start_description': node_descs[0],\n",
    "            'end_description': node_descs[-1],\n",
    "            'path_summary': ' → '.join(node_types),\n",
    "            'full_path': ' → '.join(node_descs),\n",
    "            'min_edge_weight': min(abs(w) for w in path.edges) if path.edges else 0.0,\n",
    "            'max_edge_weight': max(abs(w) for w in path.edges) if path.edges else 0.0,\n",
    "            'avg_edge_weight': sum(abs(w) for w in path.edges) / len(path.edges) if path.edges else 0.0,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df_complete = paths_to_dataframe(complete_paths, graph, model.tokenizer)\n",
    "\n",
    "print(\"Complete Paths DataFrame:\")\n",
    "print(df_complete[['rank', 'influence_score', 'length', 'path_summary']])\n",
    "print()\n",
    "\n",
    "# Save to CSV\n",
    "df_complete.to_csv('complete_paths_austin.csv', index=False)\n",
    "print(\"✅ Saved to complete_paths_austin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as LibPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory and save graph\n",
    "graph_dir = LibPath('graphs')\n",
    "graph_dir.mkdir(exist_ok=True)\n",
    "\n",
    "graph_name = 'dallas_capital_attribution.pt'\n",
    "graph_path = graph_dir / graph_name\n",
    "\n",
    "print(f\"Saving graph to {graph_path}...\")\n",
    "graph.to_pt(graph_path)\n",
    "print(f\"Graph saved successfully! (Size: {graph_path.stat().st_size / 1024 / 1024:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate graph files for interactive visualization. The pruning thresholds control how much of the graph to keep:\n",
    "- `node_threshold`: Keep minimum nodes whose cumulative influence >= this value\n",
    "- `edge_threshold`: Keep minimum edges whose cumulative influence >= this value\n",
    "\n",
    "**Graph Features:**\n",
    "- Click to select nodes\n",
    "- Ctrl/Cmd+Click to pin/unpin nodes to your subgraph\n",
    "- G+Click on nodes to group them into supernodes\n",
    "- Edit node descriptions by clicking the edit button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug = \"dallas-capital\"  # Name for this graph\n",
    "graph_file_dir = './graph_files'\n",
    "node_threshold = 0.8  # Keep nodes explaining 80% of influence\n",
    "edge_threshold = 0.98  # Keep edges explaining 98% of influence\n",
    "\n",
    "print(f\"Creating visualization files with slug '{slug}'...\")\n",
    "print(f\"Node threshold: {node_threshold}, Edge threshold: {edge_threshold}\")\n",
    "\n",
    "create_graph_files(\n",
    "    graph_or_path=graph_path,\n",
    "    slug=slug,\n",
    "    output_path=graph_file_dir,\n",
    "    node_threshold=node_threshold,\n",
    "    edge_threshold=edge_threshold\n",
    ")\n",
    "\n",
    "print(f\"Visualization files created in {graph_file_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_tracer.frontend.local_server import serve\n",
    "from IPython.display import IFrame\n",
    "\n",
    "port = 8047\n",
    "print(f\"Starting visualization server on port {port}...\")\n",
    "server = serve(data_dir='./graph_files/', port=port)\n",
    "\n",
    "print(f\"\\nVisualization server is running!\")\n",
    "print(f\"Open your graph here: http://localhost:{port}/index.html\")\n",
    "print(f\"\\nTo stop the server later, run: server.stop()\")\n",
    "\n",
    "# Display in iframe\n",
    "display(IFrame(src=f'http://localhost:{port}/index.html', width='100%', height='800px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()\n",
    "# print(\"Server stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def generate_adjacency_matrix(n, b):\n",
    "    total_nodes = n*b + 1\n",
    "    base_matrix = einops.rearrange(t.arange(total_nodes-1), '(n b) -> n b', b=b)\n",
    "    adjacency_matrix = t.zeros([total_nodes, total_nodes])\n",
    "\n",
    "    for layer, nodes in enumerate(base_matrix):\n",
    "        for token_pos, node in enumerate(nodes):\n",
    "            # print(f'layer: {layer}')\n",
    "            # print(f'token pos: {token_pos}')\n",
    "            # print(f'node: {node}')\n",
    "\n",
    "            layers_left = t.arange(layer+1, n)\n",
    "            tokens_left = t.arange(token_pos, b)\n",
    "            nodes_left_coords = t.cartesian_prod(layers_left, tokens_left)\n",
    "            \n",
    "            rows = nodes_left_coords[:, 0]\n",
    "            cols = nodes_left_coords[:, 1]\n",
    "            nodes_left = base_matrix[rows, cols]\n",
    "            \n",
    "            # print(f'coordinates of nodes left: {nodes_left_coords}')\n",
    "            # print(f'nodes left: {nodes_left}')\n",
    "            # print()\n",
    "\n",
    "            adjacency_matrix[:, node][nodes_left] = 1\n",
    "\n",
    "    adjacency_matrix[-1, :-1] = 1\n",
    "\n",
    "\n",
    "    test_n = list(range(n))\n",
    "    test_b = list(range(b))\n",
    "    test_c = [(n_i, b_i) for n_i in test_n for b_i in test_b]\n",
    "\n",
    "    node_info = dict(enumerate(test_c))\n",
    "    node_info[total_nodes-1] = (n, b-1)\n",
    "\n",
    "\n",
    "    return adjacency_matrix, node_info\n",
    "\n",
    "adjacency_matrix, node_info = generate_adjacency_matrix(n=3, b=2)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 4, 6],\n",
       " [0, 2, 5, 6],\n",
       " [0, 2, 6],\n",
       " [0, 3, 5, 6],\n",
       " [0, 3, 6],\n",
       " [0, 4, 6],\n",
       " [0, 5, 6],\n",
       " [0, 6],\n",
       " [1, 3, 5, 6],\n",
       " [1, 3, 6],\n",
       " [1, 5, 6],\n",
       " [1, 6]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_paths_wrapper(adj_matrix, b):\n",
    "    start_stack = list(range(b))\n",
    "    final_node = len(adj_matrix) - 1\n",
    "    all_paths = []\n",
    "\n",
    "    def find_all_paths(current_path):\n",
    "        assert len(current_path) >= 1\n",
    "        current_node = current_path[-1]\n",
    "        if current_node == final_node:\n",
    "            all_paths.append(current_path)\n",
    "            return\n",
    "        \n",
    "        mystack = t.nonzero(adj_matrix[:, current_node])\n",
    "        for node in mystack:\n",
    "            find_all_paths(current_path + [node.item()])\n",
    "\n",
    "\n",
    "    for node in start_stack:\n",
    "        current_path = [node]\n",
    "        find_all_paths(current_path)\n",
    "        pass\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "all_paths = find_all_paths_wrapper(\n",
    "    adjacency_matrix,\n",
    "    b=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import perm, comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_paths_length_base(i, b):\n",
    "    if i == 2:\n",
    "        return b\n",
    "\n",
    "    final_length = 0\n",
    "    for b_prime in range(b, 0, -1):\n",
    "        final_length += calculate_paths_length_base(i-1, b_prime)\n",
    "    \n",
    "    return final_length\n",
    "\n",
    "\n",
    "def calculate_paths_simple_graph(n, b):\n",
    "    def calculate_paths_length_i(i):\n",
    "        factor = comb(n-2, i-2)\n",
    "        length = calculate_paths_length_base(i, b)\n",
    "        return factor * length\n",
    "\n",
    "    all_paths = []\n",
    "    for i in range(2, n+1):\n",
    "        paths_length_i = calculate_paths_length_i(i)\n",
    "        all_paths.append(paths_length_i)\n",
    "\n",
    "    return sum(all_paths)\n",
    "\n",
    "calculate_paths_simple_graph(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 1590.99it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 834.76it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 400.11it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 224.92it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 111.73it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 39.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for n in range(2, 8):\n",
    "    for b in tqdm(range(1, 8)):\n",
    "        adj_matrix, __ = generate_adjacency_matrix(n-1, b)\n",
    "        l1 = find_all_paths_wrapper(adj_matrix, b)\n",
    "        l2 = calculate_paths_simple_graph(n, b)\n",
    "\n",
    "        # print(f'l1: {l1}')\n",
    "        # print(f'l2: {l2}')\n",
    "\n",
    "        assert len(l1) == l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating interactive visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "skip",
         "line": {
          "color": "#888",
          "width": 0.5
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0,
          null,
          0,
          100,
          null,
          100,
          100,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          100,
          null,
          100,
          100,
          null,
          0,
          100,
          null,
          100,
          100,
          null,
          0,
          100,
          null,
          100,
          100,
          null,
          0,
          100,
          null,
          100,
          100,
          null,
          0,
          100,
          null,
          100,
          100,
          null
         ],
         "y": [
          0,
          100,
          null,
          0,
          100,
          null,
          0,
          100,
          null,
          0,
          200,
          null,
          100,
          200,
          null,
          0,
          200,
          null,
          0,
          200,
          null,
          100,
          200,
          null,
          100,
          200,
          null,
          0,
          300,
          null,
          0,
          300,
          null,
          100,
          300,
          null,
          100,
          300,
          null,
          200,
          300,
          null,
          200,
          300,
          null
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Input[0]</b><br><br><b>Influenced by (0):</b><br><br><br><b>Feeds into (5):</b><br>L1[0]<br>L1[1]<br>L2[0]<br>L2[1]<br>Output",
          "<b>Input[1]</b><br><br><b>Influenced by (0):</b><br><br><br><b>Feeds into (3):</b><br>L1[1]<br>L2[1]<br>Output",
          "<b>L1[0]</b><br><br><b>Influenced by (1):</b><br>Input[0]<br><br><b>Feeds into (3):</b><br>L2[0]<br>L2[1]<br>Output",
          "<b>L1[1]</b><br><br><b>Influenced by (2):</b><br>Input[0]<br>Input[1]<br><br><b>Feeds into (2):</b><br>L2[1]<br>Output",
          "<b>L2[0]</b><br><br><b>Influenced by (2):</b><br>Input[0]<br>L1[0]<br><br><b>Feeds into (1):</b><br>Output",
          "<b>L2[1]</b><br><br><b>Influenced by (4):</b><br>Input[0]<br>Input[1]<br>L1[0]<br>L1[1]<br><br><b>Feeds into (1):</b><br>Output",
          "<b>Output</b><br><br><b>Influenced by (6):</b><br>Input[0]<br>Input[1]<br>L1[0]<br>L1[1]<br>L2[0]<br>L2[1]<br><br><b>Feeds into (0):</b><br>"
         ],
         "marker": {
          "color": "lightblue",
          "line": {
           "color": "darkblue",
           "width": 2
          },
          "size": 20
         },
         "mode": "markers+text",
         "showlegend": false,
         "text": [
          "Input[0]",
          "Input[1]",
          "L1[0]",
          "L1[1]",
          "L2[0]",
          "L2[1]",
          "Output"
         ],
         "textfont": {
          "size": 10
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0,
          100,
          0,
          100,
          0,
          100,
          100
         ],
         "y": [
          0,
          0,
          100,
          100,
          200,
          200,
          300
         ]
        }
       ],
       "layout": {
        "height": 800,
        "hovermode": "closest",
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Attribution Graph"
        },
        "width": 1200,
        "xaxis": {
         "showgrid": true,
         "showticklabels": true,
         "title": {
          "text": "Token Position"
         },
         "zeroline": false
        },
        "yaxis": {
         "showgrid": true,
         "showticklabels": true,
         "title": {
          "text": "Layer"
         },
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Interactive visualization of attribution graphs with hover functionality.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_node_label(node_idx: int, node_info: dict) -> str:\n",
    "    \"\"\"Generate a human-readable label for a node.\"\"\"\n",
    "    layer, pos = node_info[node_idx]\n",
    "    total_layers = max(l for l, _ in node_info.values())\n",
    "\n",
    "    if layer == total_layers:  # Sink node\n",
    "        return f\"Output\"\n",
    "    elif layer == 0:\n",
    "        return f\"Input[{pos}]\"\n",
    "    else:\n",
    "        return f\"L{layer}[{pos}]\"\n",
    "\n",
    "def visualize_attribution_graph(\n",
    "    adj_matrix: np.ndarray,\n",
    "    node_info: dict,\n",
    "    title: str = \"Attribution Graph\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an interactive visualization of the attribution graph.\n",
    "\n",
    "    Hovering on nodes highlights:\n",
    "    - Nodes it feeds into (outgoing edges) in green\n",
    "    - Nodes it's influenced by (incoming edges) in blue\n",
    "    \"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "\n",
    "    # Compute node positions (layer determines y, position determines x)\n",
    "    node_positions = {}\n",
    "    for node_idx, (layer, pos) in node_info.items():\n",
    "        # x: position (with spacing), y: layer (with spacing)\n",
    "        node_positions[node_idx] = (pos * 100, layer * 100)\n",
    "\n",
    "    # Create edge traces\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_hover_text = []\n",
    "\n",
    "    for target_idx in range(n_nodes):\n",
    "        for source_idx in range(n_nodes):\n",
    "            if adj_matrix[target_idx, source_idx] > 0:\n",
    "                x0, y0 = node_positions[source_idx]\n",
    "                x1, y1 = node_positions[target_idx]\n",
    "\n",
    "                edge_x.extend([x0, x1, None])\n",
    "                edge_y.extend([y0, y1, None])\n",
    "\n",
    "                source_label = get_node_label(source_idx, node_info)\n",
    "                target_label = get_node_label(target_idx, node_info)\n",
    "                edge_hover_text.append(f\"{source_label} → {target_label}\")\n",
    "\n",
    "    # Edge trace\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='skip',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    # Prepare node data\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    node_hover_info = []\n",
    "\n",
    "    for node_idx in range(n_nodes):\n",
    "        x, y = node_positions[node_idx]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "\n",
    "        label = get_node_label(node_idx, node_info)\n",
    "        node_text.append(label)\n",
    "\n",
    "        # Find incoming and outgoing edges\n",
    "        incoming_nodes = [i for i in range(n_nodes) if adj_matrix[node_idx, i] > 0]\n",
    "        outgoing_nodes = [i for i in range(n_nodes) if adj_matrix[i, node_idx] > 0]\n",
    "\n",
    "        incoming_labels = [get_node_label(i, node_info) for i in incoming_nodes]\n",
    "        outgoing_labels = [get_node_label(i, node_info) for i in outgoing_nodes]\n",
    "\n",
    "        hover_text = f\"<b>{label}</b><br>\"\n",
    "        hover_text += f\"<br><b>Influenced by ({len(incoming_nodes)}):</b><br>\"\n",
    "        hover_text += \"<br>\".join(incoming_labels[:10])  # Limit to first 10\n",
    "        if len(incoming_labels) > 10:\n",
    "            hover_text += f\"<br>... and {len(incoming_labels) - 10} more\"\n",
    "\n",
    "        hover_text += f\"<br><br><b>Feeds into ({len(outgoing_nodes)}):</b><br>\"\n",
    "        hover_text += \"<br>\".join(outgoing_labels[:10])\n",
    "        if len(outgoing_labels) > 10:\n",
    "            hover_text += f\"<br>... and {len(outgoing_labels) - 10} more\"\n",
    "\n",
    "        node_hover_info.append(hover_text)\n",
    "\n",
    "    # Node trace\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        ),\n",
    "        text=node_text,\n",
    "        textposition=\"top center\",\n",
    "        textfont=dict(size=10),\n",
    "        hovertext=node_hover_info,\n",
    "        hoverinfo='text',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[edge_trace, node_trace])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        xaxis=dict(\n",
    "            title='Token Position',\n",
    "            showgrid=True,\n",
    "            zeroline=False,\n",
    "            showticklabels=True\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Layer',\n",
    "            showgrid=True,\n",
    "            zeroline=False,\n",
    "            showticklabels=True\n",
    "        ),\n",
    "        plot_bgcolor='white',\n",
    "        width=1200,\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "print(\"\\nCreating interactive visualization...\")\n",
    "fig = visualize_attribution_graph(\n",
    "    adjacency_matrix,\n",
    "    node_info,\n",
    ")\n",
    "\n",
    "fig.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-circuit-tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
