{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_without_error_nodes(adjacency_matrix):\n",
    "    # remove the error nodes from the adjacency matrix!\n",
    "    n_features = len(graph.selected_features)\n",
    "    n_error_nodes = len(graph.input_tokens) * model.cfg.n_layers\n",
    "\n",
    "    mask = t.ones_like(adjacency_matrix[0]).to(t.bool)\n",
    "    mask[n_features : n_features + n_error_nodes] = False\n",
    "    updated_matrix = adjacency_matrix[mask][:, mask]\n",
    "\n",
    "    return updated_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topological_order(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute topological order using Kahn's algorithm.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: torch.Tensor of shape (n_nodes, n_nodes)\n",
    "                         where adjacency_matrix[target, source] represents edge from source -> target\n",
    "    \n",
    "    Returns:\n",
    "        list: Topological order of node indices\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Compute in-degrees: for each node, count how many edges point TO it\n",
    "    in_degree = (adjacency_matrix != 0).sum(dim=1).cpu()\n",
    "    \n",
    "    # Initialize queue with nodes that have no incoming edges\n",
    "    queue = [i for i in range(n_nodes) if in_degree[i] == 0]\n",
    "    topo_order = []\n",
    "    \n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        topo_order.append(node)\n",
    "        \n",
    "        # For each outgoing edge from this node\n",
    "        outgoing_edges = (adjacency_matrix[:, node] != 0).cpu()\n",
    "        \n",
    "        for target in range(n_nodes):\n",
    "            if outgoing_edges[target]:\n",
    "                in_degree[target] -= 1\n",
    "                if in_degree[target] == 0:\n",
    "                    queue.append(target)\n",
    "    \n",
    "    if len(topo_order) != n_nodes:\n",
    "        print(f\"Warning: Graph contains a cycle! Only {len(topo_order)}/{n_nodes} nodes ordered.\")\n",
    "        remaining = [i for i in range(n_nodes) if i not in topo_order]\n",
    "        topo_order.extend(remaining)\n",
    "    \n",
    "    return topo_order\n",
    "\n",
    "adjacency_matrix = graph.adjacency_matrix\n",
    "\n",
    "print(\"Computing topological order of the attribution graph...\")\n",
    "topo_order = compute_topological_order(adjacency_matrix)\n",
    "print(f\"Topological order computed: {len(topo_order)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_topological_sort(topological_sort, n_error_nodes=286):\n",
    "    '''\n",
    "    the only 'illegal moves' are  \n",
    "    (a) moving to same token, previous layer  \n",
    "    (b) moving to previous token, previous layer  \n",
    "    '''\n",
    "\n",
    "    prev_layer = -1\n",
    "    prev_token_pos = 0\n",
    "\n",
    "    for idx, node in enumerate(topological_sort[286:]):\n",
    "        layer, token_pos = get_node_details(node)\n",
    "        if (layer < prev_layer) and (token_pos <= prev_token_pos):\n",
    "            print(f'error in topological sort at idx: {idx}')\n",
    "        \n",
    "    print(f'topological sort is okay!')\n",
    "\n",
    "test_topological_sort(topo_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from circuit_tracer.graph import compute_node_influence\n",
    "\n",
    "@dataclass\n",
    "class Path:\n",
    "    \"\"\"Represents a path through the attribution graph.\"\"\"\n",
    "    nodes: List[int]\n",
    "    edges: List[float]\n",
    "    score: float\n",
    "    # averaged_score: float\n",
    "    final_score: float\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def get_node_types(self, graph) -> List[str]:\n",
    "        \"\"\"Return node types: 'feature', 'error', 'embed', 'logit'.\"\"\"\n",
    "        n_features = len(graph.selected_features)\n",
    "        n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "        n_embeds = graph.n_pos\n",
    "        \n",
    "        types = []\n",
    "        for node in self.nodes:\n",
    "            if node < n_features:\n",
    "                types.append('feature')\n",
    "            elif node < n_features + n_errors:\n",
    "                types.append('error')\n",
    "            elif node < n_features + n_errors + n_embeds:\n",
    "                types.append('embed')\n",
    "            else:\n",
    "                types.append('logit')\n",
    "        return types\n",
    "    \n",
    "    def get_node_descriptions(self, graph, tokenizer) -> List[str]:\n",
    "        \"\"\"Return human-readable descriptions for each node.\"\"\"\n",
    "        descriptions = []\n",
    "        n_features = len(graph.selected_features)\n",
    "        n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "        n_embeds = graph.n_pos\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            if node < n_features:\n",
    "                layer, pos, feat_idx = graph.active_features[graph.selected_features[node]].tolist()\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Feature L{layer}:F{feat_idx} @ pos {pos} ('{token}')\")\n",
    "            elif node < n_features + n_errors:\n",
    "                error_idx = node - n_features\n",
    "                layer = error_idx // graph.n_pos\n",
    "                pos = error_idx % graph.n_pos\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Error L{layer} @ pos {pos} ('{token}')\")\n",
    "            elif node < n_features + n_errors + n_embeds:\n",
    "                pos = node - n_features - n_errors\n",
    "                token = tokenizer.decode([graph.input_tokens[pos]])\n",
    "                descriptions.append(f\"Embedding @ pos {pos} ('{token}')\")\n",
    "            else:\n",
    "                logit_idx = node - n_features - n_errors - n_embeds\n",
    "                token = tokenizer.decode([graph.logit_tokens[logit_idx]])\n",
    "                prob = graph.logit_probabilities[logit_idx].item()\n",
    "                descriptions.append(f\"Logit '{token}' (p={prob:.4f})\")\n",
    "        \n",
    "        return descriptions\n",
    "\n",
    "\n",
    "def find_k_best_paths_dp(adj_matrix, source_nodes, sink_node, topo_order, k=10, verbose=True):\n",
    "    \"\"\"OPTIMIZED: Find top-K paths using DP. Stores lightweight references, reconstructs at end.\"\"\"\n",
    "    best_path_refs = {}\n",
    "    best_path_refs[sink_node] = [(None, None, 1.0)]\n",
    "    \n",
    "    iterator = reversed(topo_order) if not verbose else tqdm(\n",
    "        reversed(topo_order), desc=\"DP path finding (optimized)\", total=len(topo_order)\n",
    "    )\n",
    "    \n",
    "    for node in iterator:\n",
    "        if node == sink_node:\n",
    "            continue\n",
    "        \n",
    "        outgoing_weights = adj_matrix[:, node]\n",
    "        successors = t.where(outgoing_weights != 0)[0]\n",
    "        \n",
    "        if len(successors) == 0:\n",
    "            best_path_refs[node] = []\n",
    "            continue\n",
    "        \n",
    "        candidate_refs = []\n",
    "        for succ in successors:\n",
    "            succ_idx = succ.item()\n",
    "            if succ_idx not in best_path_refs or len(best_path_refs[succ_idx]) == 0:\n",
    "                continue\n",
    "            \n",
    "            edge_weight = outgoing_weights[succ].item()\n",
    "            for succ_next, succ_edge, path_score in best_path_refs[succ_idx]:\n",
    "                new_score = abs(edge_weight) * path_score\n",
    "                candidate_refs.append((succ_idx, edge_weight, new_score))\n",
    "        \n",
    "        candidate_refs.sort(key=lambda x: x[2], reverse=True)\n",
    "        best_path_refs[node] = candidate_refs[:k]\n",
    "    \n",
    "    def reconstruct_path(start_node, path_ref_index):\n",
    "        \"\"\"Reconstruct full path by following successor chain.\"\"\"\n",
    "        nodes, edges = [start_node], []\n",
    "        current_node, current_ref_idx = start_node, path_ref_index\n",
    "        \n",
    "        while True:\n",
    "            next_node, edge_weight, score = best_path_refs[current_node][current_ref_idx]\n",
    "            if next_node is None:\n",
    "                break\n",
    "            \n",
    "            nodes.append(next_node)\n",
    "            edges.append(edge_weight)\n",
    "            current_node = next_node\n",
    "            \n",
    "            target_score = score / abs(edge_weight)\n",
    "            current_ref_idx = 0\n",
    "            for i, (nn, ne, ns) in enumerate(best_path_refs[current_node]):\n",
    "                if abs(ns - target_score) < 1e-9:\n",
    "                    current_ref_idx = i\n",
    "                    break\n",
    "        \n",
    "        return Path(nodes=nodes, edges=edges, score=best_path_refs[start_node][path_ref_index][2], final_score=0.0)\n",
    "    \n",
    "    all_source_paths = []\n",
    "    for source in source_nodes:\n",
    "        if source in best_path_refs and len(best_path_refs[source]) > 0:\n",
    "            for path_idx in range(len(best_path_refs[source])):\n",
    "                all_source_paths.append(reconstruct_path(source, path_idx))\n",
    "\n",
    "    return all_source_paths\n",
    "    \n",
    "    # for path in all_source_paths:\n",
    "    #     path.averaged_score = path.score / len(path.edges)\n",
    "    #     path.final_score = sum(path.edges) / len(path.edges)\n",
    "    \n",
    "    # all_source_paths.sort(key=lambda p: p.final_score, reverse=True)\n",
    "    # return all_source_paths[:k]\n",
    "\n",
    "\n",
    "print(\"✅ Path finding functions loaded (optimized version)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define node indices\n",
    "n_features = len(graph.selected_features)\n",
    "n_errors = graph.cfg.n_layers * graph.n_pos\n",
    "n_embeds = graph.n_pos\n",
    "n_logits = len(graph.logit_tokens)\n",
    "\n",
    "embed_start = n_features + n_errors\n",
    "embed_end = embed_start + n_embeds\n",
    "embed_nodes = list(range(embed_start, embed_end))\n",
    "austin_logit = embed_end  # Index 8489\n",
    "\n",
    "print(f\"Finding top-10 complete paths: Embeddings [{embed_start}:{embed_end}] → Austin [{austin_logit}]\")\n",
    "print()\n",
    "\n",
    "# Find complete paths\n",
    "all_complete_paths = find_k_best_paths_dp(\n",
    "    adj_matrix=adjacency_matrix,\n",
    "    source_nodes=embed_nodes,\n",
    "    sink_node=austin_logit,\n",
    "    topo_order=topo_order,\n",
    "    k=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_complete_paths:\n",
    "    path.final_score = sum(path.edges) / len(path.edges)\n",
    "\n",
    "all_complete_paths_sorted = sorted(all_complete_paths, key=lambda p: p.final_score, reverse=True)\n",
    "top_k_complete_paths = all_complete_paths_sorted[:10]\n",
    "\n",
    "print(f\"\\n✅ Found {len(top_k_complete_paths)} complete paths!\")\n",
    "print()\n",
    "\n",
    "# Display paths\n",
    "for rank, path in enumerate(top_k_complete_paths, 1):\n",
    "    node_descs = path.get_node_descriptions(graph, model.tokenizer)\n",
    "    node_types = path.get_node_types(graph)\n",
    "    \n",
    "    print(f\"Path #{rank} (Score: {path.final_score:.8f}, Length: {len(path)})\")\n",
    "    print(f\"  {' → '.join(node_types)}\")\n",
    "    print(f\"  Start: {node_descs[0]}\")\n",
    "    print(f\"  End: {node_descs[-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_dataframe(paths, graph, tokenizer):\n",
    "    \"\"\"Convert list of Path objects to pandas DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for rank, path in enumerate(paths, 1):\n",
    "        node_types = path.get_node_types(graph)\n",
    "        node_descs = path.get_node_descriptions(graph, tokenizer)\n",
    "        \n",
    "        rows.append({\n",
    "            'rank': rank,\n",
    "            'influence_score': path.score,\n",
    "            'length': len(path),\n",
    "            'start_type': node_types[0],\n",
    "            'end_type': node_types[-1],\n",
    "            'start_description': node_descs[0],\n",
    "            'end_description': node_descs[-1],\n",
    "            'path_summary': ' → '.join(node_types),\n",
    "            'full_path': ' → '.join(node_descs),\n",
    "            'min_edge_weight': min(abs(w) for w in path.edges) if path.edges else 0.0,\n",
    "            'max_edge_weight': max(abs(w) for w in path.edges) if path.edges else 0.0,\n",
    "            'avg_edge_weight': sum(abs(w) for w in path.edges) / len(path.edges) if path.edges else 0.0,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df_complete = paths_to_dataframe(complete_paths, graph, model.tokenizer)\n",
    "\n",
    "print(\"Complete Paths DataFrame:\")\n",
    "print(df_complete[['rank', 'influence_score', 'length', 'path_summary']])\n",
    "print()\n",
    "\n",
    "# Save to CSV\n",
    "df_complete.to_csv('complete_paths_austin.csv', index=False)\n",
    "print(\"✅ Saved to complete_paths_austin.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-circuit-tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
